{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import scipy\n",
    "from matplotlib.pyplot import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import os\n",
    "from math import sqrt\n",
    "import json\n",
    "from statistics import mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cyclic_net(filename):\n",
    "    G=nx.read_edgelist(filename, comments='#', delimiter=\"\\t\", nodetype =str,  data=(('mode',str),), create_using=nx.DiGraph())\n",
    "    G.remove_nodes_from([\"Source\", \"Target\"])\n",
    "    selfloops=G.selfloop_edges()\n",
    "    G.remove_edges_from(G.selfloop_edges())\n",
    "    \n",
    "    while 0 in G.in_degree().values() or 0 in G.out_degree().values():\n",
    "        nodes_to_remove=[node for node in G if G.in_degree(node) == 0 or G.out_degree(node) == 0]\n",
    "        G.remove_nodes_from(nodes_to_remove)\n",
    "        \n",
    "    selfloops_in_reservoir=[edge for edge in selfloops if edge[0] in G.nodes()]\n",
    "    G.add_edges_from(selfloops_in_reservoir)\n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ESN(object):\n",
    "    def __init__(self, filename, in_size, out_size, spectral_radius):\n",
    "        self.res_size= self.build_adj_weighted_matrix(filename).shape[0]\n",
    "        self.in_size=in_size\n",
    "        self.out_size=out_size\n",
    "        self.spectral_radius= spectral_radius\n",
    "        self.W0=self.build_adj_weighted_matrix(filename)\n",
    "        self.W=None\n",
    "        self.Win=None\n",
    "        self.Wout=None\n",
    "        self.X=None\n",
    "        self.Y=None\n",
    "        self.x=np.zeros((self.res_size,1))\n",
    "        self.x0=np.random.rand(self.res_size)\n",
    "        self.decay=np.random.rand((self.res_size))*10\n",
    "\n",
    "    \n",
    "    def build_adj_weighted_matrix(self, filename):\n",
    "        net=get_cyclic_net(filename)\n",
    "        for edge in net.edges_iter(data=\"mode\", default=0):\n",
    "            source,target,mode=edge\n",
    "            if mode== \"+\":\n",
    "                net[source][target][\"weight\"]= rand.uniform(0,1)\n",
    "            elif mode== \"-\":\n",
    "                net[source][target][\"weight\"]= rand.uniform(0,-1)\n",
    "            elif mode== 0:\n",
    "                net[source][target][\"weight\"]= rand.uniform(-1,1)\n",
    "        return nx.to_numpy_matrix(net)\n",
    "    \n",
    "    def initialize(self): \n",
    "        np.random.seed(42)\n",
    "        self.Win=np.random.choice([-0.5,0.5], size=(self.res_size,1+self.in_size))\n",
    "        self.W0 = np.squeeze(np.asarray(self.W0))\n",
    "        rhoW0 = max(abs(scipy.linalg.eig(self.W0)[0]))\n",
    "        self.W= (self.spectral_radius/rhoW0)*self.W0\n",
    "        \n",
    "\n",
    "    def collect_states(self, data, init_len, train_len, a=0.3):\n",
    "        self.X=np.zeros((self.res_size+self.in_size+1, train_len-init_len))\n",
    "        for t in range(train_len):\n",
    "            u = data[t]\n",
    "            self.x = (1-a)*self.x + a*np.tanh( np.dot( self.Win, np.vstack((1,u)) ) + np.dot( self.W, self.x ) ) \n",
    "            if t >= init_len:\n",
    "                self.X[:,t-init_len]= np.vstack((1,u,self.x))[:,0]\n",
    "               \n",
    "        return self.X\n",
    "    \n",
    "    def collect_states_derivative(self, data, init_len, train_len, n=0):\n",
    "        self.X=np.zeros((self.res_size+self.in_size+1, train_len-init_len))\n",
    "        t=np.arange(train_len)\n",
    "        x=scipy.integrate.odeint(self.dx_dt,self.x0,t,args=(data,self.decay))\n",
    "        self.x0=x[-1,:]\n",
    "        for t in range(init_len-n,train_len-n):\n",
    "            x_concat=x[t,:].reshape(x[t,:].shape[0],1)\n",
    "            self.X[:,t-init_len]= np.vstack((1,data[t],x_concat))[:,0]\n",
    "               \n",
    "        return self.X\n",
    "    \n",
    "    def dx_dt(self, x,t,data,decay):\n",
    "        x_updated= np.tanh( np.dot( self.Win, np.vstack((1,data[int(t)])) ) + np.dot( self.W, x ) ) - np.multiply(decay,x)\n",
    "        return x_updated[0,:]\n",
    "        \n",
    "    \n",
    "    def calculate_weights(self, data, init_len, train_len, beta=1e-8 ):\n",
    "        Y=np.array([data[init_len:train_len]])\n",
    "        X_T=self.X.T\n",
    "        self.Wout= np.dot ( np.dot(Y, X_T), np.linalg.inv(np.dot(self.X,X_T) + beta * np.eye(self.res_size+self.in_size+1))) #w= y*x_t*(x*x_t + beta*I)^-1\n",
    "        return self.Wout\n",
    "    \n",
    "    def run_predictive(self, data, test_len, train_len,a=0.3):\n",
    "        self.Y = np.zeros((self.out_size,test_len))\n",
    "        u = data[train_len] \n",
    "        for t in range(test_len):\n",
    "            self.x = (1-a)*self.x + a*np.tanh( np.dot( self.Win, np.vstack((1,u)) ) + np.dot( self.W, self.x ) ) \n",
    "            y = np.dot( self.Wout, np.vstack((1,u,self.x)) )\n",
    "            self.Y[:,t] = y\n",
    "            u = data[train_len+t+1] \n",
    "        \n",
    "        return self.Y\n",
    "    \n",
    "    def run_predictive_derivative(self, data, test_len, train_len,dt=1):\n",
    "        self.Y = np.zeros((self.out_size,test_len))\n",
    "        u = data[train_len]\n",
    "        t=np.arange(test_len)\n",
    "        x=scipy.integrate.odeint(self.dx_dt,self.x0,t,args=(data[train_len:],self.decay))\n",
    "        for t in range(test_len-1):\n",
    "            x_concat=x[t,:].reshape(x[t,:].shape[0],1)\n",
    "            y = np.dot( self.Wout, np.vstack((1,u,x_concat)) )\n",
    "            self.Y[:,t] = y\n",
    "            u = data[train_len+t+1] \n",
    "        \n",
    "        return self.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NARMA \n",
    "def NARMA_task(steps, data, init_len, train_len):\n",
    "        Y=np.zeros(train_len)\n",
    "        for t in range(init_len,train_len):\n",
    "            Y[t]=0.3* Y[t-1] + 0.05*Y[t-1]*np.sum(Y[t-1:t-steps])+ 1.5*data[t-steps]*data[t-1]+0.1\n",
    "                \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_gene_net(directory,data):\n",
    "    csv_files= [file for file in os.listdir(directory) if file.startswith(\"network_edge_list\")]\n",
    "\n",
    "    for file in csv_files:\n",
    "        net=ESN(os.path.join(directory, file),1,1,0.95)\n",
    "        net.initialize()\n",
    "        net.collect_states(data,initLen,trainLen)\n",
    "        net.calculate_weights(data,initLen,trainLen)\n",
    "        net.run_predictive(data,testLen,trainLen)\n",
    "        \n",
    "        nrmse= sqrt(mean_squared_error(data[trainLen+1:trainLen+errorLen+1],net.Y[0,0:errorLen])/np.std(net.Y[0,0:errorLen]))\n",
    "        print(net.res_size, 'NRMSE = ' + str( nrmse ))\n",
    "        \n",
    "        \n",
    "        plot( data[trainLen+1:trainLen+testLen+1], 'g' )\n",
    "        plot( net.Y.T, 'b' )\n",
    "        title('Target and generated signals $y(n)$ starting at $n=0$')\n",
    "        legend(['Target signal', 'Free-running predicted signal'])\n",
    "        show()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_gene_net_derivative(directory,data,result):\n",
    "    csv_files= [file for file in os.listdir(directory) if file.startswith(\"network_edge_list\")]\n",
    "\n",
    "    for file in csv_files:\n",
    "        net=ESN(os.path.join(directory, file),1,1,0.95)\n",
    "        net.initialize()\n",
    "        net.collect_states_derivative(data,initLen,trainLen)\n",
    "        print(net.res_size, \" FINISHED\")\n",
    "        net.calculate_weights(data,initLen,trainLen)\n",
    "        net.run_predictive_derivative(data,testLen,trainLen)\n",
    "        nrmse= sqrt(mean_squared_error(result[trainLen+1:trainLen+errorLen+1],net.Y[0,0:errorLen])/np.std(net.Y[0,0:errorLen]))\n",
    "        print(net.res_size, 'NRMSE = ' + str( nrmse ))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_MI(x, y):\n",
    "    bins=sqrt(x.shape[0]/5)\n",
    "    c_xy = np.histogram2d(x, y, bins)[0]\n",
    "    mi = mutual_info_score(None, None, contingency=c_xy)\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory_capacity_n(Yt_n, Y,i_size):\n",
    "    MI_i={}\n",
    "    for i in range(1,2*(i_size)+1):\n",
    "        Yt_n=np.array(Yt_n)\n",
    "        MI_i[\"i\"+str(i)]=calc_MI(Y[200:800],Yt_n[0,200-i:800-i])\n",
    "    return MI_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINING AND TEST LENGHT\n",
    "errorLen = 500\n",
    "trainLen=9000\n",
    "testLen=1000\n",
    "initLen=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files= [file for file in os.listdir(\"Dataset1/\") if file.startswith(\"network_edge_list\") and not \"ENCODE\" in file]\n",
    "csv_files=sorted(csv_files)\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MACKEY GLASS\n",
    "data = np.loadtxt('MackeyGlass_t17.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"MACKEY GLASS\")\n",
    "testing_gene_net(\"Dataset1/\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NARMA TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_narma= [rand.uniform(0,0.5) for el in range(10501)]\n",
    "NARMA_result= NARMA_task(10,u_narma,initLen,len(data))\n",
    "NARMA_result[2000:4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"NARMA\")\n",
    "testing_gene_net(\"Dataset1/\",NARMA_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"With derivatives\")\n",
    "testing_gene_net_derivative(\"Dataset1/\", data, NARMA_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
